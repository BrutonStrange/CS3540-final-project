{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1cc020ff-1994-40e7-84b3-0103e79176cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#imports\n",
    "#\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f799d777-a1d3-4934-b781-8608dae23d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#defining useful functions\n",
    "#\n",
    "\n",
    "def greyscale_from_array(im, brightening_factor=1):\n",
    "    #stack the three channels side by side\n",
    "    rgb = np.hstack((im[::,::,0:1:],im[::,::,1:2:],im[::,::,2:3:]))\n",
    "\n",
    "    #change each list of one integer to just that integer\n",
    "    rgb_fixed = np.zeros((rgb.shape[0], rgb.shape[1]))\n",
    "    for i in range(rgb.shape[0]):\n",
    "        for j in range(rgb.shape[1]):\n",
    "            rgb_fixed[i][j] = rgb[i][j][0]*brightening_factor\n",
    "\n",
    "    #return the greyscale image\n",
    "    return rgb_fixed\n",
    "\n",
    "def load_images_to_dict(key=\"stack\", folder=\"train\"):\n",
    "    #for switching between \"train\", \"test\", and \"valid\" folders\n",
    "    path = (folder + \"/\" + folder)\n",
    "\n",
    "    #makes a dictionary mapping species to all the files in that folder\n",
    "    directories = {}\n",
    "    for species_file in os.listdir(path):\n",
    "        directories[species_file] = os.listdir(path  + \"/\" + species_file)\n",
    "\n",
    "    #makes a dictionary mapping species to arrays for each image in that folder\n",
    "    images = {}\n",
    "    for directory in directories.keys():\n",
    "        images[directory] = []\n",
    "        for file in os.listdir(path + \"/\" + directory): \n",
    "            if key == \"stack\":\n",
    "                array = np.array(Image.open(path + \"/\" + directory + \"/\" + file).resize((24,36)))\n",
    "                images[directory].append(np.hstack((array[::,::,0],array[::,::,1],array[::,::,2])))\n",
    "            else:\n",
    "                images[directory].append(np.array(Image.open(path + \"/\" + directory + \"/\" + file).resize((24,36)))[::,::,key])\n",
    "\n",
    "    #return that dictionary\n",
    "    return images\n",
    "\n",
    "def build_X_y_from_dict(image_dict):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    i=0\n",
    "    for key, value in image_dict.items():\n",
    "        for image in value:\n",
    "            X.append(image)\n",
    "            y.append(i)\n",
    "        i += 1\n",
    "    \n",
    "    y = np.array(y)\n",
    "    X = np.array(X)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1]*X.shape[2]))\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def normalize_Xtest_Xtrain(X_test, X_train):\n",
    "    normalization_vector = np.zeros(X_train.shape[1])\n",
    "    std_vector = np.zeros(X_train.shape[1])\n",
    "\n",
    "\n",
    "    \n",
    "    for index in range(X_train.shape[1]):\n",
    "        normalization_vector[index] = sum(X_train[::, index])\n",
    "        std_vector[index] = np.std(X_train[::, index])\n",
    "    normalization_vector /= X_train.shape[0]\n",
    "\n",
    "\n",
    "    \n",
    "    X_test = X_test.astype('int16')\n",
    "    for index in range(X_test.shape[0]):\n",
    "        X_test[index] = X_test[index] - normalization_vector\n",
    "    \n",
    "    X_train = X_train.astype('int16')\n",
    "    for index in range(X_train.shape[0]):\n",
    "        X_train[index] = X_train[index] - normalization_vector\n",
    "\n",
    "\n",
    "    \n",
    "    return X_test, X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cfe89b84-54cb-4b39-9d48-52f856bf2ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebstr\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#train and score the data\n",
    "#\n",
    "train_images = load_images_to_dict(\"stack\")\n",
    "X_train, y_train = build_X_y_from_dict(train_images)\n",
    "test_images = load_images_to_dict(\"stack\", \"test\")\n",
    "X_test, y_test = build_X_y_from_dict(test_images)\n",
    "\n",
    "#X_test, X_train = normalize_Xtest_Xtrain(X_test, X_train)\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=100).fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc37f011-fe6b-4efa-aaad-6cd65a4b7603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
